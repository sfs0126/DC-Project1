{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "# create spark contexts\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"blogtext_preprocessing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogtext_df = spark.read.csv('/spring2021/project1/blogtext.csv',header=True, inferSchema='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk\n",
    "import preproc as pp\n",
    "\n",
    "# preproc is a python file that has functions defined to do the \"text\" column preprocessing.\n",
    "\n",
    "# Register all the functions in Preproc with Spark Context\n",
    "\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the raw columns\n",
    "raw_cols = blogtext_df.columns\n",
    "\n",
    "rm_stops_df = blogtext_df.select(raw_cols)\\\n",
    "                   .withColumn(\"stop_text\", remove_stops_udf(blogtext_df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "rm_stops_df = reduce(DataFrame.drop, ['text'], rm_stops_df)\n",
    "raw_cols = rm_stops_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_features_df = rm_stops_df.select(raw_cols)\\\n",
    "                            .withColumn(\"feat_text\", \\\n",
    "                            remove_features_udf(rm_stops_df[\"stop_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_features_df = reduce(DataFrame.drop, ['stop_text'], rm_features_df)\n",
    "\n",
    "raw_cols = rm_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df = rm_features_df.select(raw_cols) \\\n",
    "                          .withColumn(\"tagged_text\", \\\n",
    "                           tag_and_remove_udf(rm_features_df.feat_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df = reduce(DataFrame.drop, ['feat_text'], tagged_df)\n",
    "\n",
    "raw_cols = tagged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_df = tagged_df.select(raw_cols) \\\n",
    "                   .withColumn(\"text\", lemmatize_udf(tagged_df[\"tagged_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_df = reduce(DataFrame.drop, ['tagged_text'], lemm_df)\n",
    "\n",
    "raw_cols = lemm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemm_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|info find page pd...|\n",
      "|team member drewe...|\n",
      "|het kader van ker...|\n",
      "|           test test|\n",
      "|thanks yahoo tool...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blog_df = lemm_df.select(\"text\")\n",
    "blog_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['info find page pdf file wait untill team leader process learns html'],\n",
       " ['team member drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering urllink mail']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_rdd = blog_df.rdd.map(list)\n",
    "blog_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'info find page pdf file wait untill team leader process learns html'\",\n",
       " \"'team member drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering urllink mail'\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "blog_rdd = blog_rdd.map(lambda x: re.sub('\\[|\\]', '', str(x)))\n",
    "blog_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'info\", 'find']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_rdd = blog_rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "blog_rdd.take(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'info\", 1), ('find', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_rdd_count = blog_rdd.map(lambda word: (word, 1))\n",
    "blog_rdd_count.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 14146),\n",
       " ('scott', 5485),\n",
       " ('format', 3283),\n",
       " ('step', 22933),\n",
       " ('risk', 6768)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_rdd_count_RBK = blog_rdd_count.reduceByKey(lambda x, y: (x + y))\n",
    "blog_rdd_count_RBK.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(762164, 'get'),\n",
       " (499790, 'go'),\n",
       " (428069, 'know'),\n",
       " (424555, 'time'),\n",
       " (419093, 'think')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_rdd1 = blog_rdd_count_RBK.map(lambda x: (x[1],x[0])).sortByKey(ascending=False)\n",
    "blog_rdd1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|    _1|   _2|\n",
      "+------+-----+\n",
      "|762164|  get|\n",
      "|499790|   go|\n",
      "|428069| know|\n",
      "|424555| time|\n",
      "|419093|think|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blog_df1 = spark.createDataFrame(blog_rdd1)\n",
    "blog_df1.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|blog_words|\n",
      "+----------+\n",
      "|       get|\n",
      "|        go|\n",
      "|      know|\n",
      "|      time|\n",
      "|     think|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blog_df2 = blog_df1.select(\"_2\")\n",
    "blog_df2 = blog_df2.withColumnRenamed(\"_2\", \"blog_words\")\n",
    "blog_df2.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_rdd = sc.textFile(\"/spring2021/project1/ddss/PrideClean.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(x):\n",
    "    lower_string = x.lower()\n",
    "    punctuation = '!\"#$%&\\'“”()*+,./:'';’<=>?@[\\\\]^_`{|}~-—1234567890'\n",
    "    for i in punctuation:\n",
    "        lower_string = lower_string.replace(i, '')\n",
    "    return lower_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(61, 'chapter'), (858, 'is'), (12, 'single'), (1862, 'in'), (9, 'possession'), (3599, 'of'), (182, 'good'), (308, 'must'), (134, 'however'), (57, 'known')]\n"
     ]
    }
   ],
   "source": [
    "pride_rdd = pride_rdd.map(clean_string)\n",
    "pride_rdd = pride_rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "pride_rdd = pride_rdd.filter(lambda x: x != '')\n",
    "pride_rdd_count = pride_rdd.map(lambda word: (word, 1))\n",
    "pride_rdd_count_RBK = pride_rdd_count.reduceByKey(lambda x, y: (x + y))\n",
    "pride_rdd_count_RBK = pride_rdd_count_RBK.map(lambda x:(x[1], x[0]))\n",
    "print(pride_rdd_count_RBK.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "newStopWords = ['mrs','mr','could','would','though','said','one','like']\n",
    "stopwords.extend(newStopWords)\n",
    "\n",
    "#stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'rightful'),\n",
       " (1, 'grownup'),\n",
       " (1, 'newcomers'),\n",
       " (1, 'overscrupulous'),\n",
       " (1, 'vexing'),\n",
       " (1, 'solace'),\n",
       " (1, 'disclosed'),\n",
       " (1, 'hat'),\n",
       " (1, 'coughing'),\n",
       " (1, 'stress')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pride_rdd_count_RBK = pride_rdd_count_RBK.filter(lambda x: x[0] not in stopwords).sortByKey()\n",
    "pride_rdd_count_RBK.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| _1|            _2|\n",
      "+---+--------------+\n",
      "|  1|      rightful|\n",
      "|  1|       grownup|\n",
      "|  1|     newcomers|\n",
      "|  1|overscrupulous|\n",
      "|  1|        vexing|\n",
      "+---+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pride_df = spark.createDataFrame(pride_rdd_count_RBK)\n",
    "pride_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|   pride_words|\n",
      "+--------------+\n",
      "|      rightful|\n",
      "|       grownup|\n",
      "|     newcomers|\n",
      "|overscrupulous|\n",
      "|        vexing|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pride_df1 = pride_df.select(\"_2\")\n",
    "pride_df1 = pride_df1.withColumnRenamed(\"_2\", \"pride_words\")\n",
    "pride_df1.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|pride_words|blog_words|\n",
      "+-----------+----------+\n",
      "|   rightful|       get|\n",
      "|   rightful|        go|\n",
      "|   rightful|      know|\n",
      "|   rightful|      time|\n",
      "|   rightful|     think|\n",
      "+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pride_blog = pride_df1.crossJoin(blog_df2)\n",
    "pride_blog.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+\n",
      "|pride_words|blog_words|levenshtein|\n",
      "+-----------+----------+-----------+\n",
      "|   rightful|       get|          6|\n",
      "|   rightful|        go|          7|\n",
      "|   rightful|      know|          8|\n",
      "|   rightful|      time|          7|\n",
      "|   rightful|     think|          7|\n",
      "|   rightful|       say|          8|\n",
      "|   rightful|      nbsp|          8|\n",
      "|   rightful|      make|          8|\n",
      "|   rightful|       day|          8|\n",
      "|   rightful|     thing|          7|\n",
      "|   rightful|       see|          8|\n",
      "|   rightful|      want|          7|\n",
      "|   rightful|    people|          8|\n",
      "|   rightful|   urllink|          8|\n",
      "|   rightful|      come|          8|\n",
      "|   rightful|      good|          7|\n",
      "|   rightful|      take|          7|\n",
      "|   rightful|      work|          8|\n",
      "|   rightful|      look|          8|\n",
      "|   rightful|      love|          8|\n",
      "+-----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "pride_blog = pride_blog.withColumn(\"levenshtein\", F.levenshtein(F.col(\"pride_words\"), F.col(\"blog_words\")))\n",
    "pride_blog.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------+\n",
      "|pride_words|blog_words|levenshtein|\n",
      "+-----------+----------+-----------+\n",
      "|  newcomers|  newcomer|          1|\n",
      "|     solace|    solace|          0|\n",
      "|  disclosed|  disclose|          1|\n",
      "|        hat|       eat|          1|\n",
      "|        hat|      hate|          1|\n",
      "|        hat|       hit|          1|\n",
      "|        hat|       hot|          1|\n",
      "|        hat|       cat|          1|\n",
      "|        hat|       fat|          1|\n",
      "|        hat|       hat|          0|\n",
      "|        hat|       wat|          1|\n",
      "|        hat|      chat|          1|\n",
      "|        hat|      heat|          1|\n",
      "|        hat|       sat|          1|\n",
      "|        hat|       dat|          1|\n",
      "|        hat|       tat|          1|\n",
      "|        hat|       pat|          1|\n",
      "|        hat|       rat|          1|\n",
      "|        hat|       bat|          1|\n",
      "|        hat|       hav|          1|\n",
      "+-----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pride_blog.filter(\"levenshtein < 2\").show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_rdd = sc.textFile(\"/spring2021/project1/ddss/MobyCleanChaptersOnly.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(172, 'chapter'), (54, 'call'), (93, 'years'), (77, 'mind'), (313, 'long'), (563, 'no'), (10, 'money'), (4050, 'in'), (7, 'purse'), (49, 'particular')]\n"
     ]
    }
   ],
   "source": [
    "moby_rdd = moby_rdd.map(clean_string)\n",
    "moby_rdd = moby_rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "moby_rdd = moby_rdd.filter(lambda x: x != '')\n",
    "moby_rdd_count = moby_rdd.map(lambda word: (word, 1))\n",
    "moby_rdd_count_RBK = moby_rdd_count.reduceByKey(lambda x, y: (x + y))\n",
    "moby_rdd_count_RBK = moby_rdd_count_RBK.map(lambda x:(x[1], x[0]))\n",
    "print(moby_rdd_count_RBK.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'regulating'),\n",
       " (1, 'circulation'),\n",
       " (1, 'offthen'),\n",
       " (1, 'philosophical'),\n",
       " (1, 'manhattoes'),\n",
       " (1, 'coenties'),\n",
       " (1, 'seeposted'),\n",
       " (1, 'spiles'),\n",
       " (1, 'lath'),\n",
       " (1, 'plastertied')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_rdd_count_RBK = moby_rdd_count_RBK.filter(lambda x: x[0] not in stopwords).sortByKey()\n",
    "moby_rdd_count_RBK.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| _1|           _2|\n",
      "+---+-------------+\n",
      "|  1|   regulating|\n",
      "|  1|  circulation|\n",
      "|  1|      offthen|\n",
      "|  1|philosophical|\n",
      "|  1|   manhattoes|\n",
      "+---+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moby_df = spark.createDataFrame(moby_rdd_count_RBK)\n",
    "moby_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|   moby_words|\n",
      "+-------------+\n",
      "|   regulating|\n",
      "|  circulation|\n",
      "|      offthen|\n",
      "|philosophical|\n",
      "|   manhattoes|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moby_df1 = moby_df.select(\"_2\")\n",
    "moby_df1 = moby_df1.withColumnRenamed(\"_2\", \"moby_words\")\n",
    "moby_df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|moby_words|blog_words|\n",
      "+----------+----------+\n",
      "|regulating|       get|\n",
      "|regulating|        go|\n",
      "|regulating|      know|\n",
      "|regulating|      time|\n",
      "|regulating|     think|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moby_blog = moby_df1.crossJoin(blog_df2)\n",
    "moby_blog.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+\n",
      "|moby_words|blog_words|levenshtein|\n",
      "+----------+----------+-----------+\n",
      "|regulating|       get|          8|\n",
      "|regulating|        go|          9|\n",
      "|regulating|      know|         10|\n",
      "|regulating|      time|          8|\n",
      "|regulating|     think|          8|\n",
      "|regulating|       say|          9|\n",
      "|regulating|      nbsp|         10|\n",
      "|regulating|      make|          9|\n",
      "|regulating|       day|          9|\n",
      "|regulating|     thing|          7|\n",
      "|regulating|       see|          9|\n",
      "|regulating|      want|          8|\n",
      "|regulating|    people|          8|\n",
      "|regulating|   urllink|          7|\n",
      "|regulating|      come|         10|\n",
      "|regulating|      good|          9|\n",
      "|regulating|      take|          9|\n",
      "|regulating|      work|         10|\n",
      "|regulating|      look|          9|\n",
      "|regulating|      love|          9|\n",
      "+----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moby_blog = moby_blog.withColumn(\"levenshtein\", F.levenshtein(F.col(\"moby_words\"), F.col(\"blog_words\")))\n",
    "moby_blog.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----------+\n",
      "|   moby_words|   blog_words|levenshtein|\n",
      "+-------------+-------------+-----------+\n",
      "|  circulation|  circulation|          0|\n",
      "|philosophical|philosophical|          0|\n",
      "|         lath|         late|          1|\n",
      "|         lath|         math|          1|\n",
      "|         lath|         path|          1|\n",
      "|         lath|         bath|          1|\n",
      "|         lath|          lah|          1|\n",
      "|         lath|         lash|          1|\n",
      "|         lath|         hath|          1|\n",
      "|         lath|         lata|          1|\n",
      "|         lath|        latch|          1|\n",
      "|         lath|         oath|          1|\n",
      "|     counters|      counter|          1|\n",
      "|        desks|         desk|          1|\n",
      "|        shady|        shade|          1|\n",
      "|        shady|        shady|          0|\n",
      "|        shady|        shaky|          1|\n",
      "|      attract|      attract|          0|\n",
      "|         dale|         date|          1|\n",
      "|         dale|         sale|          1|\n",
      "+-------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moby_blog.filter(\"levenshtein < 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatsby_rdd = sc.textFile(\"/spring2021/project1/ddss/GatsbyClean.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37, 'once'), (56, 'again'), (3, 'wear'), (7, 'gold'), (5, 'hat'), (10, 'move'), (392, 'her'), (2, 'bounce'), (17, 'high'), (7, 'till')]\n"
     ]
    }
   ],
   "source": [
    "gatsby_rdd = gatsby_rdd.map(clean_string)\n",
    "gatsby_rdd = gatsby_rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "gatsby_rdd = gatsby_rdd.filter(lambda x: x != '')\n",
    "gatsby_rdd_count = gatsby_rdd.map(lambda word: (word, 1))\n",
    "gatsby_rdd_count_RBK = gatsby_rdd_count.reduceByKey(lambda x, y: (x + y))\n",
    "gatsby_rdd_count_RBK = gatsby_rdd_count_RBK.map(lambda x:(x[1], x[0]))\n",
    "print(gatsby_rdd_count_RBK.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'highbouncing'),\n",
       " (1, 'parke'),\n",
       " (1, 'dinvilliers'),\n",
       " (1, 'advantages'),\n",
       " (1, 'inclined'),\n",
       " (1, 'natures'),\n",
       " (1, 'victim'),\n",
       " (1, 'veteran'),\n",
       " (1, 'bores'),\n",
       " (1, 'abnormal')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby_rdd_count_RBK = gatsby_rdd_count_RBK.filter(lambda x: x[0] not in stopwords).sortByKey()\n",
    "gatsby_rdd_count_RBK.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| _1|          _2|\n",
      "+---+------------+\n",
      "|  1|highbouncing|\n",
      "|  1|       parke|\n",
      "|  1| dinvilliers|\n",
      "|  1|  advantages|\n",
      "|  1|    inclined|\n",
      "+---+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gatsby_df = spark.createDataFrame(gatsby_rdd_count_RBK)\n",
    "gatsby_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|gatsby_words|\n",
      "+------------+\n",
      "|highbouncing|\n",
      "|       parke|\n",
      "| dinvilliers|\n",
      "|  advantages|\n",
      "|    inclined|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gatsby_df1 = gatsby_df.select(\"_2\")\n",
    "gatsby_df1 = gatsby_df1.withColumnRenamed(\"_2\", \"gatsby_words\")\n",
    "gatsby_df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|gatsby_words|blog_words|\n",
      "+------------+----------+\n",
      "|highbouncing|       get|\n",
      "|highbouncing|        go|\n",
      "|highbouncing|      know|\n",
      "|highbouncing|      time|\n",
      "|highbouncing|     think|\n",
      "+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gatsby_blog = gatsby_df1.crossJoin(blog_df2)\n",
    "gatsby_blog.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------+\n",
      "|gatsby_words|blog_words|levenshtein|\n",
      "+------------+----------+-----------+\n",
      "|highbouncing|       get|         11|\n",
      "|highbouncing|        go|         10|\n",
      "|highbouncing|      know|         11|\n",
      "|highbouncing|      time|         11|\n",
      "|highbouncing|     think|          9|\n",
      "|highbouncing|       say|         12|\n",
      "|highbouncing|      nbsp|         11|\n",
      "|highbouncing|      make|         12|\n",
      "|highbouncing|       day|         12|\n",
      "|highbouncing|     thing|          8|\n",
      "|highbouncing|       see|         12|\n",
      "|highbouncing|      want|         11|\n",
      "|highbouncing|    people|         11|\n",
      "|highbouncing|   urllink|         10|\n",
      "|highbouncing|      come|         11|\n",
      "|highbouncing|      good|         10|\n",
      "|highbouncing|      take|         12|\n",
      "|highbouncing|      work|         11|\n",
      "|highbouncing|      look|         11|\n",
      "|highbouncing|      love|         11|\n",
      "+------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gatsby_blog = gatsby_blog.withColumn(\"levenshtein\", F.levenshtein(F.col(\"gatsby_words\"), F.col(\"blog_words\")))\n",
    "gatsby_blog.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----------+\n",
      "|gatsby_words| blog_words|levenshtein|\n",
      "+------------+-----------+-----------+\n",
      "|       parke|       park|          1|\n",
      "|       parke|     parker|          1|\n",
      "|       parke|     parked|          1|\n",
      "|  advantages|  advantage|          1|\n",
      "|    inclined|    incline|          1|\n",
      "|    inclined|   inclined|          0|\n",
      "|     natures|     nature|          1|\n",
      "|      victim|     victim|          0|\n",
      "|     veteran|    veteran|          0|\n",
      "|       bores|       bore|          1|\n",
      "|       bores|      bored|          1|\n",
      "|       bores|      bore'|          1|\n",
      "|    abnormal|   abnormal|          0|\n",
      "|     appears|     appear|          1|\n",
      "|  politician| politician|          0|\n",
      "| confidences| confidence|          1|\n",
      "| fundamental|fundamental|          0|\n",
      "|   tolerance|  tolerance|          0|\n",
      "|    glimpses|    glimpse|          1|\n",
      "|      exempt|     exempt|          0|\n",
      "+------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gatsby_blog.filter(\"levenshtein < 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
